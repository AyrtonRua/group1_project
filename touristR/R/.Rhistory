since =   sinceInput[1]  ,
until = lubridate::today(tzone = Sys.timezone()) %>% lubridate::ymd() %>% as.character()  ,
#specifying the geocode to be sure we only obtain e.g. indeed
#the results published from Paris for search query Paris (tweet should
#be made within a radius of 40 miles from Paris maximum)
geocode = paste(df[i, ]$lat, df[i, ]$long, "40mi", sep = ",")
)
results_twitter = list()  # saving result in a list
#PROBLEM HERE
for (i in 1:length(keyword)) {
#run query for that keyword (format is #... without any space)
#first we remove any white space to obtain oneword input
keyword_input[i] <-
gsub(keyword[i], pattern = " ", replacement = "")
#then we obtain the #oneword format to be used as input for the Twitter query
input[i] <- paste("#", keyword_input[i], sep = "")
#query Twitter using the keyword input
results_twitter[i] <-   twitteR::searchTwitter(
input[i] ,
n = n,
resultType = "mixed",
since =   sinceInput[1]  ,
until = lubridate::today(tzone = Sys.timezone()) %>% lubridate::ymd() %>% as.character()  ,
#specifying the geocode to be sure we only obtain e.g. indeed
#the results published from Paris for search query Paris (tweet should
#be made within a radius of 40 miles from Paris maximum)
geocode = paste(df[i, ]$lat, df[i, ]$long, "40mi", sep = ",")
)
}
results_twitter
#PROBLEM HERE
for (i in 1:length(keyword)) {
#run query for that keyword (format is #... without any space)
#first we remove any white space to obtain oneword input
keyword_input[i] <-
gsub(keyword[i], pattern = " ", replacement = "")
#then we obtain the #oneword format to be used as input for the Twitter query
input[i] <- paste("#", keyword_input[i], sep = "")
#query Twitter using the keyword input
results_twitter[[i]] <-   twitteR::searchTwitter(
input[i] ,
n = n,
resultType = "mixed",
since =   sinceInput[1]  ,
until = lubridate::today(tzone = Sys.timezone()) %>% lubridate::ymd() %>% as.character()  ,
#specifying the geocode to be sure we only obtain e.g. indeed
#the results published from Paris for search query Paris (tweet should
#be made within a radius of 40 miles from Paris maximum)
geocode = paste(df[i, ]$lat, df[i, ]$long, "40mi", sep = ",")
)
}
results_twitter
#saving search query results in a dataframe
results_tweetdata <-
twitteR::twListToDF(results_twitter) %>% tibble::as.tibble()
results_tweetdata
View(results_twitter)
results_twitter %>% unlist() %>% as.data.frame()
results_twitter %>% unlist()
#saving search query results in a dataframe
results_tweetdata <-
twitteR::twListToDF(results_twitter %>% unlist()) %>% tibble::as.tibble()
View(results_tweetdata)
if (  sincetype == "days" &&  number <= 14) {
#correct date format and keep it with seconds to have a very specific
#time precision level e.g. to be used during marketing campaigns
#to identify the time slots where users post the most about a given keywork
#e.g. to optimize when to run an ad during the day (when people interact/engage
#the most with our keyword=>more engagement increases the visibility of the company)
#and for a tourist useful to know e.g. what is the current hot spot e.g. coffee shop to go to now
#a resaonable time frame to aggregate results is hours in that sense
results_tweetdata$created <-
lubridate::ymd_hms(results_tweetdata$created,
tz = Sys.timezone(),
quiet = TRUE) %>%
lubridate::round_date(unit =  "hour")
#plot
print(
results_tweetdata %>%
dplyr::group_by(city, created) %>% dplyr::count() %>% dplyr::arrange() %>% dplyr::rename(count =
n) %>%
ggplot2::ggplot() +
ggplot2::geom_line(
mapping = ggplot2::aes(x = created, count),
size = 1,
alpha = 1
) +
ggplot2::scale_y_continuous(
breaks = scales::pretty_breaks(8),
labels = scales::number_format(accuracy = 1)
) +
ggplot2::labs(
title =  paste(
paste("Twitter #", keyword, sep = ""),
"popularity tracking"   ,
sep = " "
),
caption = paste(
"Note: Hourly data (UTC time) fetched from",
format(as.Date(sinceInput[1]), "%A, %d-%b. %Y")
,
"until",
format(as.Date(Sys.Date()), "%A, %d-%b. %Y"),".",
sep = " "
),
x = "Days",
y = "Number of tweets posted"
) +
ggplot2::theme_minimal() +
ggplot2::theme(
axis.title = ggplot2::element_text(size = 12, face = "bold"),
plot.caption = ggplot2::element_text(size = 10,face = "italic",hjust = 0),
plot.title = ggplot2::element_text(size = 14,face = "bold"),
axis.text.x = ggplot2::element_text(size=8),axis.text.y = ggplot2::element_text(size=8)
) +
ggplot2::theme(plot.margin = ggplot2::unit(c(2,10,2,2), "mm"))
)
} else
if(sincetype == "weeks" && number < 3) {
#correct date format and keep it with seconds to have a very specific
#time precision level e.g. to be used during marketing campaigns
#to identify the time slots where users post the most about a given keywork
#e.g. to optimize when to run an ad during the day (when people interact/engage
#the most with our keyword=>more engagement increases the visibility of the company)
#and for a tourist useful to know e.g. what is the current hot spot e.g. coffee shop to go to now
#a resaonable time frame to aggregate results is hours in that sense
results_tweetdata$created <-
lubridate::ymd_hms(results_tweetdata$created,
tz = Sys.timezone(),
quiet = TRUE) %>%
lubridate::round_date(unit =  "hour")
#plot
print(
results_tweetdata %>%
dplyr::group_by(city, created) %>% dplyr::count() %>% dplyr::arrange() %>% dplyr::rename(count =
n) %>%
ggplot2::ggplot() +
ggplot2::geom_line(
mapping = ggplot2::aes(x = created, count),
size = 2,
alpha = 0.8
) +
ggplot2::scale_y_continuous(
breaks = scales::pretty_breaks(8),
labels = scales::number_format(accuracy = 1)
) +
ggplot2::labs(
title =  paste(
paste("Twitter #", keyword, sep = ""),
"popularity tracking"   ,
sep = " "
),
caption = paste(
"Note: Hourly data (UTC time) fetched from",
format(as.Date(sinceInput[1]), "%A, %d-%b. %Y")
,
"until",
format(as.Date(Sys.Date()), "%A, %d-%b. %Y"),".",
sep = " "
),
x = "Days",
y = "Number of tweets posted"
) +
ggplot2::theme_minimal() +
ggplot2::theme(
axis.title = ggplot2::element_text(size = 12, face = "bold"),
plot.caption = ggplot2::element_text(size = 10,face = "italic",hjust = 0),
plot.title = ggplot2::element_text(size = 14,face = "bold"),
axis.text.x = ggplot2::element_text(size=8),axis.text.y = ggplot2::element_text(size=8)
) +
ggplot2::theme(plot.margin = ggplot2::unit(c(2,10,2,2), "mm"))
)
}
View(results_tweetdata)
View(results_tweetdata)
View(results_twitter)
View(results_twitter)
View(results_tweetdata)
#loop query on Twitter
for (i in 1:length(keyword)) {
#run query for that keyword (format is #... without any space)
#first we remove any white space to obtain oneword input
keyword_input[i] <-
gsub(keyword[i], pattern = " ", replacement = "")
#then we obtain the #oneword format to be used as input for the Twitter query
input[i] <- paste("#", keyword_input[i], sep = "")
#query Twitter using the keyword input
results_twitter[[i]] <-   twitteR::searchTwitter(
input[i] ,
n = n,
resultType = "mixed",
since =   sinceInput[1]  ,
until = lubridate::today(tzone = Sys.timezone()) %>% lubridate::ymd() %>% as.character()  ,
#specifying the geocode to be sure we only obtain e.g. indeed
#the results published from Paris for search query Paris (tweet should
#be made within a radius of 40 miles from Paris maximum)
geocode = paste(df[i, ]$lat, df[i, ]$long, "40mi", sep = ",")
)
}
results_twitter
results_twitter[[1][[1]]
results_twitter[[1][1]
results_twitter[[1]][1]
View(results_tweetdata)
results_twitter[[1]][1] %>% unlist()
View(results_twitter)
#PROBLEM FROM HERE
results_twittertest <- results_twitter
View(results_twittertest)
#saving search query results in a dataframe
results_tweetdata <-
twitteR::twListToDF(results_twittertest %>% unlist()) %>% tibble::as.tibble()
View(results_tweetdata)
#PROBLEM FROM HERE
results_twittertest = list()  # saving result in a list
results_twittertest <- results_twitter
View(results_twitter)
View(results_twittertest)
View(results_twittertest)
results_twittertest[[1]][1]
#PROBLEM FROM HERE
results_twittertest = list()  # saving result in a list
results_twittertest <- results_twitter
results_twittertest[[1]][1]
results_twittertest[[1]][1]@created
results_twittertest[[1]]@created
results_twittertest[[1]][[1]]
results_twittertest[[1]][[1]]@created
getSlots(     results_twittertest[[1]][[1]]      )
slotNames(     results_twittertest[[1]][[1]]      )
slotNames(     results_twittertest[[1]][[2]]      )
isS4(     results_twittertest[[1]][[1]]      )
results_twittertest[[1]][[1]].->created
results_twittertest[[1]][[1]]$created
results_twittertest[[1]][[1]]$blabla <- "ddj"
as(results_twittertest, status) <- "value"
as( results_twittertest[[1]][[1]], status) <- "value"
as( results_twittertest[[1]][[1]], "status") <- "value"
results_twittertest@status
results_twittertest[[1]][[1]]@create
results_twittertest[[1]][[1]]@created
results_twittertest[[1]][[1]]$created
showMethods(results_twittertest)
searchTwitter
twitteR::searchTwitter
View(results_twittertest)
results_twittertest[[1]][[1]]$created
results_twittertest[[1]][[1]]$created <- "ddj"
results_twittertest[[1]][[1]]$created <- as.character(   results_twittertest[[1]][[1]]$created )
View(results_tweetdata)
input
results_tweetdatatest
results_tweetdata$keyword <-
results_tweetertest
View(results_twittertest)
results_twittertest
View(results_twitter)
results_twittertest[[1]][[1]]$screenName
results_tweetdata$keyword <-
results_twittertest[[1]][[1]]$screenName
results_twittertest[[1]][[1]]$screenName
results_twittertest[[1]][[1]]$screenName
st <- twitteR::statusFactory$new(text="test", text="test message")
st
#loop query on Twitter
for (i in 1:length(keyword)) {
#run query for that keyword (format is #... without any space)
#first we remove any white space to obtain oneword input
keyword_input[i] <-
gsub(keyword[i], pattern = " ", replacement = "")
#then we obtain the #oneword format to be used as input for the Twitter query
input[i] <- paste("#", keyword_input[i], sep = "")
#query Twitter using the keyword input
results_twitter[[i]] <-   twitteR::searchTwitter(
input[i] ,
n = n,
resultType = "mixed",
since =   sinceInput[1]  ,
until = lubridate::today(tzone = Sys.timezone()) %>% lubridate::ymd() %>% as.character()  ,
#specifying the geocode to be sure we only obtain e.g. indeed
#the results published from Paris for search query Paris (tweet should
#be made within a radius of 40 miles from Paris maximum)
geocode = paste(df[i, ]$lat, df[i, ]$long, "40mi", sep = ",")
)
}
View(results_twitter)
View(results_twittertest)
results_twittertest[[1:2]
#adding the city name
for (i in 1:length(keyword)) {
results_tweetdata$city <-
}
#creating the plot of keyword count per day over time (measure of popularity)
if (  sincetype == "days" &&  number <= 14) {
#correct date format and keep it with seconds to have a very specific
#time precision level e.g. to be used during marketing campaigns
#to identify the time slots where users post the most about a given keywork
#e.g. to optimize when to run an ad during the day (when people interact/engage
#the most with our keyword=>more engagement increases the visibility of the company)
#and for a tourist useful to know e.g. what is the current hot spot e.g. coffee shop to go to now
#a resaonable time frame to aggregate results is hours in that sense
results_tweetdata$created <-
lubridate::ymd_hms(results_tweetdata$created,
tz = Sys.timezone(),
quiet = TRUE) %>%
lubridate::round_date(unit =  "hour")
#plot
print(
results_tweetdata %>%
dplyr::group_by(city, created) %>% dplyr::count() %>% dplyr::arrange() %>% dplyr::rename(count =
n) %>%
ggplot2::ggplot() +
ggplot2::geom_line(
mapping = ggplot2::aes(x = created, count),
size = 1,
alpha = 1
) +
ggplot2::scale_y_continuous(
breaks = scales::pretty_breaks(8),
labels = scales::number_format(accuracy = 1)
) +
ggplot2::labs(
title =  paste(
paste("Twitter #", keyword, sep = ""),
"popularity tracking"   ,
sep = " "
),
caption = paste(
"Note: Hourly data (UTC time) fetched from",
format(as.Date(sinceInput[1]), "%A, %d-%b. %Y")
,
"until",
format(as.Date(Sys.Date()), "%A, %d-%b. %Y"),".",
sep = " "
),
x = "Days",
y = "Number of tweets posted"
) +
ggplot2::theme_minimal() +
ggplot2::theme(
axis.title = ggplot2::element_text(size = 12, face = "bold"),
plot.caption = ggplot2::element_text(size = 10,face = "italic",hjust = 0),
plot.title = ggplot2::element_text(size = 14,face = "bold"),
axis.text.x = ggplot2::element_text(size=8),axis.text.y = ggplot2::element_text(size=8)
) +
ggplot2::theme(plot.margin = ggplot2::unit(c(2,10,2,2), "mm"))
)
} else
if(sincetype == "weeks" && number < 3) {
#correct date format and keep it with seconds to have a very specific
#time precision level e.g. to be used during marketing campaigns
#to identify the time slots where users post the most about a given keywork
#e.g. to optimize when to run an ad during the day (when people interact/engage
#the most with our keyword=>more engagement increases the visibility of the company)
#and for a tourist useful to know e.g. what is the current hot spot e.g. coffee shop to go to now
#a resaonable time frame to aggregate results is hours in that sense
results_tweetdata$created <-
lubridate::ymd_hms(results_tweetdata$created,
tz = Sys.timezone(),
quiet = TRUE) %>%
lubridate::round_date(unit =  "hour")
#plot
print(
results_tweetdata %>%
dplyr::group_by(city, created) %>% dplyr::count() %>% dplyr::arrange() %>% dplyr::rename(count =
n) %>%
ggplot2::ggplot() +
ggplot2::geom_line(
mapping = ggplot2::aes(x = created, count),
size = 2,
alpha = 0.8
) +
ggplot2::scale_y_continuous(
breaks = scales::pretty_breaks(8),
labels = scales::number_format(accuracy = 1)
) +
ggplot2::labs(
title =  paste(
paste("Twitter #", keyword, sep = ""),
"popularity tracking"   ,
sep = " "
),
caption = paste(
"Note: Hourly data (UTC time) fetched from",
format(as.Date(sinceInput[1]), "%A, %d-%b. %Y")
,
"until",
format(as.Date(Sys.Date()), "%A, %d-%b. %Y"),".",
sep = " "
),
x = "Days",
y = "Number of tweets posted"
) +
ggplot2::theme_minimal() +
ggplot2::theme(
axis.title = ggplot2::element_text(size = 12, face = "bold"),
plot.caption = ggplot2::element_text(size = 10,face = "italic",hjust = 0),
plot.title = ggplot2::element_text(size = 14,face = "bold"),
axis.text.x = ggplot2::element_text(size=8),axis.text.y = ggplot2::element_text(size=8)
) +
ggplot2::theme(plot.margin = ggplot2::unit(c(2,10,2,2), "mm"))
)
}
else  {
results_tweetdata$created <-
lubridate::ymd_hms(results_tweetdata$created,
tz = Sys.timezone(),
quiet = TRUE) %>% lubridate::as_date()
print(
results_tweetdata %>%  dplyr::group_by(city,created) %>% dplyr::count() %>% dplyr::arrange() %>% dplyr::rename(count =
n) %>%
ggplot2::ggplot() +
ggplot2::geom_line(
mapping = ggplot2::aes(x = created, count),
size = 2,
alpha = 0.8
) +
ggplot2::scale_y_continuous(
breaks = scales::pretty_breaks(8),
labels = scales::number_format(accuracy = 1)
) +
ggplot2::labs(
title =  paste(
paste("Twitter #", keyword, sep = "")     ,
"popularity tracking"   ,
sep = " "
)    ,
caption = paste(
"Note: Daily data (UTC time) fetched from",
format(as.Date(sinceInput[1]), "%A, %d-%b. %Y")
,
"until",
format(as.Date(Sys.Date()), "%A, %d-%b. %Y"),".",
sep = " "
),
x = "Days",
y = "Number of tweets posted"
) +
ggplot2::theme_minimal() +
ggplot2::theme(
axis.title = ggplot2::element_text(size = 12, face = "bold"),
plot.caption = ggplot2::element_text(size = 10,face = "italic",hjust = 0),
plot.title = ggplot2::element_text(size = 14,face = "bold"),
axis.text.x = ggplot2::element_text(size=8),axis.text.y = ggplot2::element_text(size=8)
) +
ggplot2::theme(plot.margin = ggplot2::unit(c(2,10,2,2), "mm"))
)
#for longer timeframe we aggregate data daily to smooth the variations of the dataset
}
#return dataframe results as well
return(results_tweetdata)
}
#needed to specify the geocode to avoid getting irrelevant content
#then input this into the twitter search page
#example to be removed at the end =>keep only function and #' (document it ) in this file
result <-
track_keyword(keyword  = c("new york","milano", "sidney"),
number = 1,
sincetype = "weeks")
results_twittertest[[1:2]]
results_twittertest[[1:2]]
results_twittertest[[,1,2]]
results_twittertest[[1,2]]
results_twittertest[[1,2]]
results_twittertest[[1,1]]
dim(results_twittertest)
twitteR::searchTwitter
View(results_twitter)
results_twitter[[1]]
results_twitter[[1]][[1]][[".->favorited"]]
results_twitter[[1]][[1]][[".->text"]]
View(results_twitter[[1]][[1]][[".->urls"]])
results_twitter[[1]][[1]][[".refClassDef"]]
View(results_twitter[[1]][[1]][["urls"]])
results_twitter[[1]][[1]][[".refClassDef"]]
View(results_tweetdata)
grep(pattern="#", results_tweetdata$text)
grepl(pattern="#", results_tweetdata$text)
sub(pattern="#", results_tweetdata$text)
grep(pattern="#", results_tweetdata$text)
grep(pattern="#", results_tweetdata$text,value=TRUE)
grep(pattern="#", results_tweetdata$text,value=TRUE,fixed=T)
grep(pattern="#paris", results_tweetdata$text,value=TRUE,fixed=T)
#  results_tweetdata$keyword <-
iii <- gsub(results_tweetdata$text, pattern = " ", replacement = "")
grep(pattern="#paris", iii,value=TRUE,fixed=T)
grep(pattern="#.*s", esults_tweetdata$text,value=TRUE,fixed=T)
grep(pattern="#.*s", results_tweetdata$text,value=TRUE,fixed=T)
grep(pattern="#[A-z]", results_tweetdata$text,value=TRUE,fixed=T)
results_tweetdata$text
grep(pattern="#paris", results_tweetdata$text,value=TRUE,fixed=T)
View(results_tweetdata)
View(results_tweetdata)
View(results_tweetdata)
Authenticate?
)
}
Authenticate?
library(vosonSML)
Authenticate?
library(vosonSML)
#Authenticate
authentication <-
vosonSML::Authenticate(
"twitter",
apiKey = "QGkK4T5I6IsOFsM7UokyM1pGC",
apiSecret = "jnZx2Lg0mNEuEDPX9g4ydi7z5Rt7WothdWYfp5q6vtGXzqdQqO",
accessToken = "1688753005-kAy1jHIirZkGlIoUlIggzsuwIae2EgyA7XJ8gFQ",
accessTokenSecret = "y3ZzJun64BaAYekFK7jybZeloGQ3J54iOkdA0aI0vomM7"
)
shiny::runApp('~/Desktop/courses 2nd year/Autumn semester 2018/Programming Tools in Data Science/FINAL HOMEWORKS/Project/group1_project/touristR/inst/shinyApp')
library(twitteR)
